# Test Execution System for AI Development Monitor

This system enhances the AI Development Monitor to ensure test scenarios are not only generated but also executed, with results verified and documented during the monitoring process.

## Overview

The test execution system integrates with the existing TDD workflow to:

1. Execute tests generated by the AI Development Monitor
2. Verify test results against implementations
3. Document test outcomes and pass/fail status
4. Display execution results in the TDD Dashboard

## Components

The system consists of multiple integrated components:

- **`test_execution.py`**: Core module with test execution functionality
- **`tdd_evaluator.py`**: Updated to integrate test execution results
- **`tdd_helpers.py`**: Enhanced to execute tests during TDD cycles
- **VS Code Extension**: Updated to display test execution results
- **Examples**: Added demonstrations of test execution functionality

## Features

- **Language Support**: Python, JavaScript, TypeScript, Java, C++, C# and others
- **C++23 Features**: Enhanced support for modern C++ features
- **Test Results**: Detailed metrics on test pass/fail status
- **Error Analysis**: Capture and display test error information
- **Execution Time**: Track and report test execution performance
- **Documentation**: Structured test result documentation

## Usage

### In TDD Flow

Test execution is automatically integrated into the TDD workflow:

1. Tests are generated for each TDD iteration
2. The system executes the tests against the implementation
3. Results are captured, verified, and documented
4. The TDD Dashboard displays execution results

### Direct Usage

You can directly use the test execution functionality via the provided utility:

```bash
./examples/run_test_execution.py \
    --test path/to/test_file.py \
    --impl path/to/implementation.py \
    --language python \
    --task "Implement a sorting algorithm" \
    --iteration 1 \
    --output report.json
```

### C++23 Example

To run the C++23 specific example:

```bash
cd examples/cpp23
./execute_cpp23_tests.sh
```

## Integration Points

### 1. Test Execution Module

The `test_execution.py` module provides the core functionality:

```python
from src.test_execution import execute_tests

result = execute_tests(
    test_code="...", 
    implementation_code="...",
    language="cpp",
    iteration=1,
    task_description="..."
)

print(f"Tests: {result.passed_tests}/{result.total_tests}")
```

### 2. TDD Evaluation

Test execution results are factored into TDD evaluation:

```python
from src.tdd_evaluator import evaluate_tdd_results

evaluation = evaluate_tdd_results(
    tdd_tests=[...],  # Now includes execution results
    suggestion_code="...",
    task_description="..."
)
```

## Configuration

The test execution system automatically detects the appropriate test framework based on the language. Advanced configuration options can be set in `config.json`:

```json
{
  "test_execution": {
    "timeout": 30,
    "frameworks": {
      "python": "pytest",
      "javascript": "jest",
      "typescript": "jest",
      "cpp": "gtest"
    }
  }
}
```

## Requirements

- For Python tests: pytest
- For JavaScript/TypeScript: Node.js with Jest
- For C++: GTest and a C++23 compatible compiler (clang-19 recommended)
- For Java: JUnit and JDK

## Documentation

For more details, see the following documentation:

- [Test Execution Guide](docs/test_execution.md)
- [TDD Flow](docs/tdd_flow.md)
- [C++23 Support](docs/cpp23_support.md)
